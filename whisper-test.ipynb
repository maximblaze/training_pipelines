{"cells":[{"cell_type":"code","execution_count":6,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","editable":false,"execution":{"iopub.execute_input":"2023-09-18T09:46:40.726009Z","iopub.status.busy":"2023-09-18T09:46:40.725440Z","iopub.status.idle":"2023-09-18T09:46:40.814401Z","shell.execute_reply":"2023-09-18T09:46:40.813485Z","shell.execute_reply.started":"2023-09-18T09:46:40.725976Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import torch\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","train_data_path = []\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        train_data_path.append(os.path.join(dirname, filename))\n","        \n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":33,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-09-18T09:54:37.002084Z","iopub.status.busy":"2023-09-18T09:54:37.001710Z","iopub.status.idle":"2023-09-18T09:55:09.726154Z","shell.execute_reply":"2023-09-18T09:55:09.724747Z","shell.execute_reply.started":"2023-09-18T09:54:37.002053Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting git+https://github.com/openai/whisper.git\n","  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-m50y0tx7\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-m50y0tx7\n","  Resolved https://github.com/openai/whisper.git to commit e8622f9afc4eba139bf796c210f5c01081000472\n","  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20230314) (2.0.0)\n","Requirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20230314) (0.57.1)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20230314) (1.23.5)\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20230314) (2.0.0+cpu)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20230314) (4.66.1)\n","Requirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20230314) (9.1.0)\n","Requirement already satisfied: tiktoken==0.3.3 in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20230314) (0.3.3)\n","Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken==0.3.3->openai-whisper==20230314) (2023.6.3)\n","Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken==0.3.3->openai-whisper==20230314) (2.31.0)\n","Requirement already satisfied: cmake in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->openai-whisper==20230314) (3.27.5)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->openai-whisper==20230314) (3.12.2)\n","Requirement already satisfied: lit in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->openai-whisper==20230314) (16.0.6)\n","Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->openai-whisper==20230314) (0.40.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20230314) (4.6.3)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20230314) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20230314) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20230314) (3.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (3.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->openai-whisper==20230314) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->openai-whisper==20230314) (1.3.0)\n"]}],"source":["! pip install git+https://github.com/openai/whisper.git"]},{"cell_type":"code","execution_count":7,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-09-18T09:46:43.634208Z","iopub.status.busy":"2023-09-18T09:46:43.633767Z","iopub.status.idle":"2023-09-18T09:46:43.640633Z","shell.execute_reply":"2023-09-18T09:46:43.639074Z","shell.execute_reply.started":"2023-09-18T09:46:43.634174Z"},"trusted":true},"outputs":[],"source":["# разные режимы датасета \n","DATA_MODES = ['train', 'val', 'test']\n","# все изображения будут масштабированы к размеру 224x224 px. Размер, хорошо воспринимаемый сетями, предобученными на ImageNet\n","RESCALE_SIZE = 224\n","# работаем на видеокарте\n","DEVICE = torch.device(\"cuda\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import io\n","import torch\n","from scipy.io import wavfile\n","import torchaudio\n","from torch.utils.data import Dataset\n","import whisper\n","from pydub import AudioSegment\n","\n","class CustomAudioDataset(Dataset):\n","    \"\"\"\n","    Датасет с картинками, который паралельно подгружает их из папок\n","    производит скалирование и превращение в торчевые тензоры, а также добавляет аугментации\n","    \"\"\"\n","    def __init__(self, mode, files, labels=None, train_transforms=None, val_test_transforms=None):\n","        super().__init__()\n","        # список файлов для загрузки\n","        self.files = files\n","        # режим работы\n","        self.mode = mode\n","\n","        if self.mode not in DATA_MODES:\n","            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n","            raise NameError\n","\n","        self.len_ = len(self.files)\n","\n","        self.train_transforms = train_transforms\n","        self.val_test_transforms = val_test_transforms\n","\n","        if self.mode != 'test':\n","            self.labels = labels\n","\n","    def __len__(self):\n","        return self.len_\n","\n","    def load_audio_sample(self, file):\n","\n","#        audio_bytes = file.read()\n","#        wav_readed = wavfile.read(io.BytesIO(audio_bytes))[1]\n","#        audio = torch.from_numpy(wav_readed)\n","\n","        # sound = AudioSegment.from_mp3(file)   #если данные в формате mp3 переведем их в wav\n","        # file = sound.export(format=\"wav\")\n","\n","        # audio = torchaudio.load(file)[0]  #for other models may be better\n","\n","        audio = whisper.audio.load_audio(file)  #only for whisper - special format\n","        return audio\n","\n","    def __getitem__(self, index):\n","        # введем тут наши аугментации для train и val/test данных.\n","        x = self.load_audio_sample(self.files[index])\n","\n","        if self.mode == 'train':\n","            if self.train_transforms:\n","                transform = self.train_transforms\n","                x = transform(x)\n","        else:\n","            if self.val_test_transforms:\n","                transform = self.val_test_transforms\n","                x = transform(x)\n","        if self.mode == 'test':\n","            return x\n","        else:\n","            label = self.labels[index]\n","            y = label\n","            return x, y"]},{"cell_type":"code","execution_count":64,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-09-18T10:06:33.803936Z","iopub.status.busy":"2023-09-18T10:06:33.803492Z","iopub.status.idle":"2023-09-18T10:06:33.818770Z","shell.execute_reply":"2023-09-18T10:06:33.817381Z","shell.execute_reply.started":"2023-09-18T10:06:33.803901Z"},"trusted":true},"outputs":[],"source":["import io\n","import torch\n","from scipy.io import wavfile\n","import torchaudio\n","from torch.utils.data import Dataset\n","import whisper\n","\n","class CustomAudioDataset(Dataset):\n","    \"\"\"\n","    Датасет с картинками, который паралельно подгружает их из папок\n","    производит скалирование и превращение в торчевые тензоры, а также добавляет аугментации\n","    \"\"\"\n","    def __init__(self, mode, files, labels=None, train_transforms=None, val_test_transforms=None):\n","        super().__init__()\n","        # список файлов для загрузки\n","        self.files = files\n","        # режим работы\n","        self.mode = mode\n","\n","        if self.mode not in DATA_MODES:\n","            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n","            raise NameError\n","\n","        self.len_ = len(self.files)\n","        \n","        self.train_transforms = train_transforms\n","        self.val_test_transforms = val_test_transforms\n","        \n","        if self.mode != 'test':\n","            self.labels = labels\n","                      \n","    def __len__(self):\n","        return self.len_\n","      \n","    def load_audio_sample(self, file):\n","        \n","#        audio_bytes = file.read()\n","#        wav_readed = wavfile.read(io.BytesIO(audio_bytes))[1]\n","#        audio = torch.from_numpy(wav_readed)\n","        \n","        #audio = torchaudio.load(file)[0] - for other models may be better\n","        audio = whisper.audio.load_audio(file)  #only for whisper - special format\n","        return audio\n","  \n","    def __getitem__(self, index):\n","        # введем тут наши аугментации для train и val/test данных. \n","        x = self.load_audio_sample(self.files[index])\n","        \n","        if self.mode == 'train':\n","            if self.train_transforms:\n","                transform = self.train_transforms\n","                x = transform(x)\n","        else:\n","            if self.val_test_transforms:\n","                transform = self.val_test_transforms\n","                x = transform(x)\n","        if self.mode == 'test':\n","            return x\n","        else:\n","            label = self.labels[index]\n","            y = label\n","            return x, y"]},{"cell_type":"code","execution_count":20,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-09-18T09:48:57.514827Z","iopub.status.busy":"2023-09-18T09:48:57.514371Z","iopub.status.idle":"2023-09-18T09:48:58.784419Z","shell.execute_reply":"2023-09-18T09:48:58.783112Z","shell.execute_reply.started":"2023-09-18T09:48:57.514793Z"},"trusted":true},"outputs":[],"source":["import urllib\n","\n","url = 'https://storage.googleapis.com/kagglesdsdata/datasets/5793/9812/cv-other-dev/cv-other-dev/sample-000000.mp3?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20230918%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20230918T093235Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=79ca3eb29b8806900432c0eddbcd92bed8f94937e8ad310da3f050bb8faca5dc595fc5bd42d8a1360ef2f61c0a18684b9bb15ee01569f3ed78a25f6ef75e5b5f30ae410a994b02ddcc1c9c7ee7c44167c496ce3133fc03e67bf52ee4c7624391b143da9ceaa221b4c4499aa8999190dff6c77a8f18a980930766ad452c4b3e8eec91ee5dcc24c052f7e0bc59afcbcc73ab06b733fe0dcd017cb72bce6c628ebca3068bf318b336bb3186a9f52ae2c4899ffcf89ac84a3d9b2b0f43836b7e87edd10d3349eee3d740d24822ef04d515718faad514508e264d426bc31bd45cd261a660b323b86f0efa5989e47d96ce01ee8735392c10a195f1f95dc01b8302c6c7'\n","            \n","urllib.request.urlretrieve(url, '/kaggle/working/test_audio.mp3')\n","            \n","audio_path = '/kaggle/working/test_audio.mp3'"]},{"cell_type":"code","execution_count":21,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-09-18T09:48:58.786720Z","iopub.status.busy":"2023-09-18T09:48:58.786318Z","iopub.status.idle":"2023-09-18T09:48:58.792519Z","shell.execute_reply":"2023-09-18T09:48:58.790953Z","shell.execute_reply.started":"2023-09-18T09:48:58.786685Z"},"trusted":true},"outputs":[],"source":["from pathlib import Path\n","audio_bytes = Path(audio_path).read_bytes()"]},{"cell_type":"code","execution_count":82,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-09-18T10:16:54.669377Z","iopub.status.busy":"2023-09-18T10:16:54.668870Z","iopub.status.idle":"2023-09-18T10:16:54.866307Z","shell.execute_reply":"2023-09-18T10:16:54.865044Z","shell.execute_reply.started":"2023-09-18T10:16:54.669343Z"},"trusted":true},"outputs":[],"source":["from pydub import AudioSegment\n","sound = AudioSegment.from_mp3(audio_path)\n","sound.export('/kaggle/working/test_audio.wav', format=\"wav\")\n","wav_form = sound.export(format=\"wav\") "]},{"cell_type":"code","execution_count":83,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-09-18T10:17:01.913164Z","iopub.status.busy":"2023-09-18T10:17:01.912779Z","iopub.status.idle":"2023-09-18T10:17:01.921019Z","shell.execute_reply":"2023-09-18T10:17:01.919799Z","shell.execute_reply.started":"2023-09-18T10:17:01.913135Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<_io.BufferedRandom name=53>"]},"execution_count":83,"metadata":{},"output_type":"execute_result"}],"source":["wav_form"]},{"cell_type":"code","execution_count":65,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-09-18T10:06:37.923718Z","iopub.status.busy":"2023-09-18T10:06:37.923264Z","iopub.status.idle":"2023-09-18T10:06:37.929634Z","shell.execute_reply":"2023-09-18T10:06:37.928328Z","shell.execute_reply.started":"2023-09-18T10:06:37.923684Z"},"trusted":true},"outputs":[],"source":["train_data_path = ['/kaggle/working/test_audio.wav']"]},{"cell_type":"code","execution_count":66,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-09-18T10:06:38.383711Z","iopub.status.busy":"2023-09-18T10:06:38.383280Z","iopub.status.idle":"2023-09-18T10:06:38.389235Z","shell.execute_reply":"2023-09-18T10:06:38.388340Z","shell.execute_reply.started":"2023-09-18T10:06:38.383677Z"},"trusted":true},"outputs":[],"source":["dataset_test = CustomAudioDataset(mode='test', files=train_data_path)"]},{"cell_type":"code","execution_count":67,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-09-18T10:06:38.745318Z","iopub.status.busy":"2023-09-18T10:06:38.744332Z","iopub.status.idle":"2023-09-18T10:06:38.751852Z","shell.execute_reply":"2023-09-18T10:06:38.750853Z","shell.execute_reply.started":"2023-09-18T10:06:38.745279Z"},"trusted":true},"outputs":[{"data":{"text/plain":["1"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["len(dataset_test)"]},{"cell_type":"code","execution_count":68,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-09-18T10:06:39.251854Z","iopub.status.busy":"2023-09-18T10:06:39.251184Z","iopub.status.idle":"2023-09-18T10:06:39.365121Z","shell.execute_reply":"2023-09-18T10:06:39.363607Z","shell.execute_reply.started":"2023-09-18T10:06:39.251820Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["dataset_test[0]"]},{"cell_type":"code","execution_count":47,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-09-18T09:58:08.573264Z","iopub.status.busy":"2023-09-18T09:58:08.572817Z","iopub.status.idle":"2023-09-18T09:58:52.348551Z","shell.execute_reply":"2023-09-18T09:58:52.347626Z","shell.execute_reply.started":"2023-09-18T09:58:08.573232Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|█████████████████████████████████████| 1.42G/1.42G [00:23<00:00, 65.4MiB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Model is multilingual and has 762,321,920 parameters.\n"]}],"source":["import whisper\n","model = whisper.load_model(\"medium\")\n","print(\n","    f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n","    f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n",")"]},{"cell_type":"code","execution_count":57,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-09-18T10:00:45.160815Z","iopub.status.busy":"2023-09-18T10:00:45.160331Z","iopub.status.idle":"2023-09-18T10:00:45.275302Z","shell.execute_reply":"2023-09-18T10:00:45.273632Z","shell.execute_reply.started":"2023-09-18T10:00:45.160779Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["audio = dataset_test[-1]\n","audio"]},{"cell_type":"code","execution_count":58,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-09-18T10:00:47.529223Z","iopub.status.busy":"2023-09-18T10:00:47.528800Z","iopub.status.idle":"2023-09-18T10:01:18.070772Z","shell.execute_reply":"2023-09-18T10:01:18.069731Z","shell.execute_reply.started":"2023-09-18T10:00:47.529193Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n","  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"]}],"source":["transcription = model.transcribe(audio, **transcribe_options)"]},{"cell_type":"code","execution_count":60,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-09-18T10:01:40.121208Z","iopub.status.busy":"2023-09-18T10:01:40.120411Z","iopub.status.idle":"2023-09-18T10:01:40.128427Z","shell.execute_reply":"2023-09-18T10:01:40.127350Z","shell.execute_reply.started":"2023-09-18T10:01:40.121171Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'text': ' She composed an emotional song in her bedroom',\n"," 'segments': [{'id': 0,\n","   'seek': 0,\n","   'start': 0.0,\n","   'end': 2.64,\n","   'text': ' She composed an emotional song in her bedroom',\n","   'tokens': [50364, 1240, 18204, 364, 6863, 2153, 294, 720, 11211, 50496],\n","   'temperature': 0.0,\n","   'avg_logprob': -0.30467835339632904,\n","   'compression_ratio': 0.8823529411764706,\n","   'no_speech_prob': 0.05771972984075546}],\n"," 'language': 'English'}"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["transcription"]},{"cell_type":"code","execution_count":79,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-09-18T10:12:26.017975Z","iopub.status.busy":"2023-09-18T10:12:26.017555Z","iopub.status.idle":"2023-09-18T10:12:26.024690Z","shell.execute_reply":"2023-09-18T10:12:26.023447Z","shell.execute_reply.started":"2023-09-18T10:12:26.017943Z"},"trusted":true},"outputs":[],"source":["transcribe_options = dict(language='English', beam_size=5, best_of=5)\n","translate_options = dict(language='Russian', beam_size=5, best_of=5)\n","\n","transcribe_options = dict(task=\"transcribe\", **transcribe_options)\n","translate_options = dict(task=\"translate\", **translate_options)"]},{"cell_type":"code","execution_count":80,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-09-18T10:12:28.131500Z","iopub.status.busy":"2023-09-18T10:12:28.131058Z","iopub.status.idle":"2023-09-18T10:13:27.782122Z","shell.execute_reply":"2023-09-18T10:13:27.780718Z","shell.execute_reply.started":"2023-09-18T10:12:28.131466Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4cde2ab455cc46fb8643dcce1d924b32","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n","  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"]}],"source":["from tqdm.notebook import tqdm\n","references = []\n","transcriptions = []\n","translations = []\n","ids = []\n","for i, audio in tqdm(enumerate(dataset_test)):\n","    transcription = model.transcribe(audio, **transcribe_options)[\"text\"]\n","    translation = model.transcribe(audio, **translate_options)[\"text\"]\n","\n","    transcriptions.append(transcription)\n","    translations.append(translation)\n","    ids.append(i)"]},{"cell_type":"code","execution_count":81,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-09-18T10:13:27.785308Z","iopub.status.busy":"2023-09-18T10:13:27.784816Z","iopub.status.idle":"2023-09-18T10:13:27.802838Z","shell.execute_reply":"2023-09-18T10:13:27.801001Z","shell.execute_reply.started":"2023-09-18T10:13:27.785265Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>transcription</th>\n","      <th>translation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>She composed an emotional song in her bedroom</td>\n","      <td>She composed an emotional song in her bedroom.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   ID                                   transcription  \\\n","0   0   She composed an emotional song in her bedroom   \n","\n","                                       translation  \n","0   She composed an emotional song in her bedroom.  "]},"execution_count":81,"metadata":{},"output_type":"execute_result"}],"source":["data = pd.DataFrame(dict(ID=ids, transcription=transcriptions, translation=translations))\n","data"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
