{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Look at the data","metadata":{"id":"mDnTgrmWLtyA"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n!pip install pymorphy2\nimport re\nfrom pymorphy2 import MorphAnalyzer\nfrom functools import lru_cache\nfrom nltk.corpus import stopwords\n\nfrom multiprocessing import Pool\nfrom tqdm import tqdm\n\nimport nltk\nnltk.download('stopwords')\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\n\nnp.random.seed(42)\nrandom.seed(42)","metadata":{"id":"GFRzNmDLjMtY","outputId":"cff755da-58ef-4ebd-84b0-1211c718d357"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Предварительно загрузим все данные на гугл диск, чтобы работать на мощностях Google Colab","metadata":{}},{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/drive')","metadata":{"id":"eiXxNCJbdsAm","outputId":"f534fe82-c3f5-47b6-e033-85f5fce2e5ff"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/content/drive/MyDrive/hse-nlp-bootcamp/train_ml.csv')\ndf","metadata":{"id":"2FofdInPjoN6","outputId":"d424763c-93fc-4d85-a916-ca7c421e4c04"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# First EDA and Time Features Creating","metadata":{"id":"TPXVA-dfj6Fj"}},{"cell_type":"markdown","source":"Сразу видим, что в столбце с целевой переменной (`grades`) есть пропуски. Удалим просто строки с пропусками в целевой переменной (не будем ничего с ними придумывать).\n\nПосмотрим предварительно еще, есть ли пропуски в признаках","metadata":{"id":"lu7vo5tNj9ZJ"}},{"cell_type":"code","source":"df.info()","metadata":{"id":"AQNQeWVpjzuP","outputId":"5904c528-f334-4d8c-f9fb-4b8765ac5069"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Сразу преобразуем столбец с меткой времени к соответствующему формату. И удалим строчки с пропусками в таргете","metadata":{"id":"_H-YQ_CAk4JU"}},{"cell_type":"code","source":"df.dtypes","metadata":{"id":"GvCc_u239RC3","outputId":"4f2371dc-79dd-43f5-f147-a0eac0d56967"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['date'] = pd.to_datetime(df['date'], format='%d.%m.%Y %H:%M')\ndf = df.dropna()\ndf = df.astype({'grades': 'int32'})\ndf","metadata":{"id":"F85oQ7rtkgjJ","outputId":"e6d54fa3-ebbc-4d4f-fd05-1dffea5ae9e6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Разберемся с фичами времени\n\n*   Сделаем фичи Год, Месяц, День\n*   А также фичу \"время суток\" из данных по часам и минутам (утро, день, вечер, ночь)\n\n","metadata":{"id":"cHamjHVOn0iH"}},{"cell_type":"code","source":"def time_day(hour):\n  if 0 <= hour < 6:\n    return 'night'\n  elif 6 <= hour < 12:\n    return 'morning'\n  if 12 <= hour < 18:\n    return 'afternoon'\n  if 18 <= hour < 24:\n    return 'evening'","metadata":{"id":"NCHRb8KTnP4W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['year'] = df['date'].apply(lambda item: item.year)\ndf['month'] = df['date'].apply(lambda item: item.month)\ndf['day'] = df['date'].apply(lambda item: item.day)\ndf['time_day'] = df['date'].apply(lambda item: time_day(item.hour))","metadata":{"id":"EedvE7gamRce"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"id":"LsnkAZK4n24J","outputId":"17893276-e90a-43c8-b2bb-cb7a3ac348c4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Посмотрим на распределение числа отзывов по банкам","metadata":{"id":"TUsxBFZnnKuj"}},{"cell_type":"code","source":"feeds_by_bank_count = df.bank.value_counts()\nfeeds_by_bank_count","metadata":{"id":"7LzTWzLemyjX","outputId":"caef2dfb-57ac-44cd-bc74-60bd4ceef635"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(40,20))\nsns.histplot(data=df.sort_values(by='bank'), \n             x=df.bank, )\nplt.xticks(rotation=45)\nplt.show()","metadata":{"id":"h0csgEzHnOhY","outputId":"46adeb44-a220-4f51-a4b6-7aaf93952963"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Глянем на распределение клиентских оценок","metadata":{"id":"18LUZxLrnO9j"}},{"cell_type":"code","source":"df.grades.value_counts().sort_index()","metadata":{"id":"_sMQ6Je0rdYu","outputId":"d3a37aff-212b-4c5e-8045-78ffedd3b046"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 10))\nsns.histplot(data=df, \n             x=df.grades, )\nplt.show()","metadata":{"id":"vvInXxbWnSyR","outputId":"4bce7ebc-7dcb-4bdc-82cf-f0084a67132d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Также нас интересуют длины отзывов","metadata":{"id":"Ku_rgep8ntN8"}},{"cell_type":"code","source":"df['sym_len'] = df.feeds.apply(len)\ndf['word_len'] = df.feeds.apply(lambda x: len(x.split()))","metadata":{"id":"LZVhWl9pnzQV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nsns.histplot(data=df.sym_len)\nplt.show()","metadata":{"id":"FDcb3qGwseG6","outputId":"fe03a313-78f6-49d5-99e7-f9f0b01b31c8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 10))\nsns.histplot(data=df.word_len)\nplt.show()","metadata":{"id":"PGS9_6AWshYH","outputId":"9b4c8a0a-d4df-4b0b-f68c-c1bcccbc47f7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Обратите внимание, у распределений очень длинные хвосты","metadata":{"id":"vxoMfYTCtyF_"}},{"cell_type":"markdown","source":"Обратили, поэтому заведем логарифмированными эти фичи:","metadata":{"id":"IlyApIC_oLo8"}},{"cell_type":"code","source":"df['sym_len'] = np.log(df['sym_len'])\ndf['word_len'] = np.log(df['word_len'])","metadata":{"id":"lemoqmbdoQhD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['sym_len'].hist()","metadata":{"id":"U-FoZFrwoZS_","outputId":"af62c5c1-ec13-477e-8100-6ceffc7ad06b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['word_len'].hist()","metadata":{"id":"7142ikXCodoe","outputId":"4ec2cd05-0c8a-44b2-e563-4b40c75e18fe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lemmas creating","metadata":{"id":"-SSSpK_bt0zj"}},{"cell_type":"markdown","source":"Подготавливаем тексты отзывов","metadata":{"id":"i54zKXPvmNuv"}},{"cell_type":"code","source":"m = MorphAnalyzer()\nregex = re.compile(\"[А-Яа-яA-z]+\")\n\ndef words_only(text, regex=regex):\n    try:\n        return regex.findall(text.lower())\n    except:\n        return []\n\n@lru_cache(maxsize=128)\ndef lemmatize_word(token, pymorphy=m):\n    return pymorphy.parse(token)[0].normal_form\n\ndef lemmatize_text(text):\n    return [lemmatize_word(w) for w in text]\n\n\nmystopwords = stopwords.words('russian') \ndef remove_stopwords(lemmas, stopwords = mystopwords):\n    return [w for w in lemmas if not w in stopwords and len(w) > 3]\n\ndef clean_text(text):\n    tokens = words_only(text)\n    lemmas = lemmatize_text(tokens)\n    \n    return ' '.join(remove_stopwords(lemmas))","metadata":{"id":"4X505UWzttrx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from multiprocessing import Pool as PoolSklearn\nwith PoolSklearn(4) as p:\n    lemmas = list(tqdm(p.imap(clean_text, df['feeds']), total=len(df)))\n    \ndf['lemmas'] = lemmas\ndf.sample(5)","metadata":{"id":"RRl4LEu4tYBx","outputId":"4f5fa0e2-7d6c-461d-9b79-f6a0f218f4b5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['grades'].hist()","metadata":{"id":"3pmSlrTHPTd6","outputId":"a81b4bdc-d6b8-4b01-c22f-924614965365"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['bank'].value_counts()","metadata":{"id":"aDqp5e3vQORJ","outputId":"78128fff-78e8-4fec-c480-f6007f51a030"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df['bank']=='sberbank']['grades'].hist()","metadata":{"id":"I56erL2xQCOk","outputId":"5deab45e-3f35-4d55-a639-eb3a506abcc3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.pairplot(df, hue='grades')","metadata":{"id":"Zq9xafJSPxq2","outputId":"988ad1fb-8a88-437d-8b43-32d97a5a2419"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pipeline. Catboost","metadata":{"id":"9MkAf1oDomNu"}},{"cell_type":"markdown","source":"Будем использовать catboost. В catboost встроен хороший обработчик текстовых фичей. Он проводит при желании все операции на GPU, что делает обучение очень быстрым.","metadata":{"id":"cYlv-6XdNtr7"}},{"cell_type":"code","source":"!pip install catboost","metadata":{"id":"Q1-HeBDpccjp","outputId":"c97f6da5-1956-46eb-dec6-8a3f66dbb537"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from catboost import CatBoostClassifier\nfrom catboost import Pool\n\n#подбор параметров не включаю в ноутбук, чтобы не засорять. Оставлю только лучшую модель\n\ndef fit_model(train_pool, validation_pool, **kwargs):\n    model = CatBoostClassifier(\n        iterations=25000,\n        learning_rate=0.009,\n        eval_metric='MultiClass',\n        #early_stopping_rounds=30,\n        use_best_model= True,\n        task_type='GPU',\n        **kwargs\n    )\n\n    return model.fit(\n        train_pool,\n        eval_set=validation_pool,\n        verbose=100,\n    )","metadata":{"id":"wxyDRJS9bnuj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"id":"8XwW_VQB9_ID","outputId":"7f33008f-1dd9-4b93-da76-5d421f994926"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split as tts\ndf.reset_index(drop=True, inplace=True)\n\ndf_train_val = df[['bank', 'feeds', 'lemmas', 'year', 'month', 'day', 'time_day', 'sym_len', 'word_len']]\ny_train_val = df['grades']\nX_train, X_val, y_train, y_val = tts(df_train_val, y_train_val, shuffle=True, stratify=y_train_val, train_size=0.8)  ","metadata":{"id":"ieWMQ-sXpxmr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_pool = Pool(\n    X_train, y_train, \n    cat_features=['bank', 'time_day', 'year', 'month', 'day'],\n    text_features=['lemmas', 'feeds'],\n)\n\nvalidation_pool = Pool(\n    X_val, y_val, \n    cat_features=['bank', 'time_day', 'year', 'month', 'day'],\n    text_features=['lemmas', 'feeds'],\n)\n\nprint('Train dataset shape: {}\\n'.format(train_pool.shape))\n\nmodel = fit_model(train_pool, validation_pool)","metadata":{"id":"XQaM-Cc2FGqn","outputId":"78b41334-ca1a-4899-eb63-aafb171223cf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Построим график важности признаков при обучении catboost:","metadata":{"id":"Mqsk4930Fte3"}},{"cell_type":"code","source":"def plot_feature_importance(importance,names,model_type):\n    \n    #Create arrays from feature importance and feature names\n    feature_importance = np.array(importance)\n    feature_names = np.array(names)\n    \n    #Create a DataFrame using a Dictionary\n    data={'feature_names':feature_names,'feature_importance':feature_importance}\n    fi_df = pd.DataFrame(data)\n    \n    #Sort the DataFrame in order decreasing feature importance\n    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n    \n    #Define size of bar plot\n    plt.figure(figsize=(10,8))\n    #Plot Searborn bar chart\n    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n    #Add chart labels\n    plt.title(model_type + 'FEATURE IMPORTANCE')\n    plt.xlabel('FEATURE IMPORTANCE')\n    plt.ylabel('FEATURE NAMES')\n#plot the catboost result\nplot_feature_importance(model.get_feature_importance(),X_train.columns,'CATBOOST ')","metadata":{"id":"k3UeL77mFxM-","outputId":"2533b90e-5c9c-47be-b9b7-43d49c5e25b5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Очевидно, фичи с текстом оказались сильно важны для обучения, добавление еще текстовых фичей, сгенерированных из этих, думаю, может помочь улучшить качество еще сильнее. Либо какие-то статистики со знаками препинания.","metadata":{"id":"CR3MorVvJqxX"}},{"cell_type":"markdown","source":"Посчитаем целевую метрику на валидации:","metadata":{"id":"ZAPxTacNJd75"}},{"cell_type":"code","source":"from sklearn.metrics import f1_score\nval_preds = model.predict(validation_pool).flatten()\nf1_score(val_preds, y_val, average='micro')","metadata":{"id":"ijleLgojGdbX","outputId":"ab7d3e7e-d1af-49af-92ee-2459a3dd7b8f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Посмотрим на confusion matrix результатов. В принципе всё очевидно, многочисленные классы лучше предсказались","metadata":{"id":"CPSfw2ZqJhzl"}},{"cell_type":"code","source":"from sklearn.datasets import make_classification\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.model_selection import train_test_split\n\ncm = confusion_matrix(y_val, val_preds)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot() ","metadata":{"id":"kjNz3_lkIMFF","outputId":"a8d1ebab-8925-48d8-e195-ce15b49d304f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"обучимся финально на почти всех имеющихся данных:","metadata":{"id":"YAnJ4T9nL-eV"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split as tts\ndf.reset_index(drop=True, inplace=True)\n\ndf_train_val = df[['bank', 'feeds', 'lemmas', 'year', 'month', 'day', 'time_day', 'sym_len', 'word_len']]\ny_train_val = df['grades']\nX_train, X_val, y_train, y_val = tts(df_train_val, y_train_val, shuffle=True, stratify=y_train_val, train_size=0.999)","metadata":{"id":"1lY7Aw6ZGZaU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_pool = Pool(\n    X_train, y_train, \n    cat_features=['bank', 'time_day', 'year', 'month', 'day'],\n    text_features=['lemmas', 'feeds'],\n)\n\nvalidation_pool = Pool(\n    X_val, y_val, \n    cat_features=['bank', 'time_day', 'year', 'month', 'day'],\n    text_features=['lemmas', 'feeds'],\n)\n\nprint('Train dataset shape: {}\\n'.format(train_pool.shape))\n\nmodel = fit_model(train_pool, validation_pool)","metadata":{"id":"T_FYMfxecb7L","outputId":"ffeacad2-bd66-4583-9b2d-0958404ef7c0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{"id":"bAp29Wk0L3Ny"}},{"cell_type":"markdown","source":"Загрузим тест. Предобработаем отзывы в нем и сделаем предсказания","metadata":{"id":"19IT2fpupy6-"}},{"cell_type":"code","source":"test = pd.read_csv('/content/drive/MyDrive/hse-nlp-bootcamp/new_test_ml.csv', index_col=0)\ntest","metadata":{"outputId":"a6c8a997-de50-485d-8588-183bb524ad69","id":"GuGMocMhpwmn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from multiprocessing import Pool as PoolSklearn\nwith PoolSklearn(4) as p:\n    lemmas = list(tqdm(p.imap(clean_text, test['feeds']), total=len(test)))\n    \ntest['lemmas'] = lemmas\ntest.sample(5)","metadata":{"id":"GaER0LDu_yHC","outputId":"9338a713-f417-4739-fcd2-852e30a19f9f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['date'] = pd.to_datetime(test['date'], format='%d.%m.%Y %H:%M')\ntest['year'] = test['date'].apply(lambda item: item.year)\ntest['month'] = test['date'].apply(lambda item: item.month)\ntest['day'] = test['date'].apply(lambda item: item.day)\ntest['time_day'] = test['date'].apply(lambda item: time_day(item.hour))\ntest['sym_len'] = np.log(test.feeds.apply(len))\ntest['word_len'] = np.log(test.feeds.apply(lambda x: len(x.split())))","metadata":{"id":"vKM1sjfpdcEd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"id":"7uzAYRXQdzeG","outputId":"6b7b6417-a09b-45dd-c347-66cede702d70"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.drop('date', axis=1, inplace=True)","metadata":{"id":"oXAu4wzyeOZY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pool = Pool(\n    test,\n    cat_features=['bank', 'time_day', 'year', 'month', 'day'],\n    text_features=['feeds', 'lemmas'],\n)\npred = model.predict(test_pool)\npred.shape","metadata":{"outputId":"63e0c748-92d1-4d36-c5bc-d86bafadcaa0","id":"i_HuBNjIpwms"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sol = pd.DataFrame({'inds': test.index,\n                    'grades': pred.flatten()})\nsol","metadata":{"outputId":"f213ad81-bfba-4f42-f2c1-4662a85bb8d8","id":"Kw4PI3WIpwms"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sol.grades.value_counts()","metadata":{"id":"lT8EvkxFen_X","outputId":"156d9422-682e-45bd-e8df-fe5f729f7eaa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sol.to_csv('new_baseline.csv', index=False)","metadata":{"id":"2xghxd6Tpwmu"},"execution_count":null,"outputs":[]}]}